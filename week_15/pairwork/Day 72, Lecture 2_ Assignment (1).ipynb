{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"},"colab":{"name":"Day 72, Lecture 2: Assignment.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"9gSTzCDSCgeC","colab_type":"text"},"source":["# Text Vectorization and Feature Engineering Assignment"]},{"cell_type":"code","metadata":{"id":"gunVMV4FCgeF","colab_type":"code","colab":{}},"source":["import pandas as pd\n","from nltk import sent_tokenize\n","from nltk import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem.snowball import SnowballStemmer\n","from nltk.stem.wordnet import WordNetLemmatizer\n","from nltk.corpus.reader.plaintext import PlaintextCorpusReader"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tra0ZNCICgeI","colab_type":"text"},"source":["### Read the CNN Lite plain text file articles into a corpus using the NLTK's PlaintextCorpusReader."]},{"cell_type":"code","metadata":{"id":"iVzAYR4CCgeJ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BmAR8xjPCgeM","colab_type":"text"},"source":["### Iterate through the fileids in the corpus, extract the raw text of each document, and store them in a list."]},{"cell_type":"code","metadata":{"id":"e9k2CshRCgeM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rhj0bcsqCgeO","colab_type":"text"},"source":["### Preprocess and clean the documents according to the steps below.\n","\n","- Word Tokenize\n","- Lowercase\n","- Remove Stopwords\n","- Remove Punctuation\n","- Lemmatize\n","- Stem"]},{"cell_type":"code","metadata":{"id":"-_-hyZd6CgeP","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ws4b33ZUCgeR","colab_type":"text"},"source":["### Count vectorize the preprocessed documents."]},{"cell_type":"code","metadata":{"id":"7LUrhKyACgeS","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zs5UbfvBCgeU","colab_type":"text"},"source":["### One hot vectorize the preprocessed documents."]},{"cell_type":"code","metadata":{"id":"TTwAIFI5CgeU","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HsUHIRZnCgeW","colab_type":"text"},"source":["### TF-IDF vectorize the preprocessed documents."]},{"cell_type":"code","metadata":{"id":"mN10u75HCgeX","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1tyf1oG4CgeZ","colab_type":"text"},"source":["### Use Doc2Vec to vectorize the preprocessed documents.\n","\n","Set the size of the vectors to be the same size as those of the other methods using the `vector_size` argument."]},{"cell_type":"code","metadata":{"id":"Q4HgOxv6CgeZ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}