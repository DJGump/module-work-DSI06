{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IihPCGvd34PH"
   },
   "source": [
    "# Text Acquisition & Ingestion Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# !pip install feedparser\\n# !pip install bs4\\n# !pip install lxml\\n# !pip install nltk\";\n",
       "                var nbb_formatted_code = \"# !pip install feedparser\\n# !pip install bs4\\n# !pip install lxml\\n# !pip install nltk\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !pip install feedparser\n",
    "# !pip install bs4\n",
    "# !pip install lxml\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"from nltk.corpus.reader.plaintext import PlaintextCorpusReader\";\n",
       "                var nbb_formatted_code = \"from nltk.corpus.reader.plaintext import PlaintextCorpusReader\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhLA_w7p34PM"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"import json\\nimport requests\\nimport feedparser\\nfrom bs4 import BeautifulSoup\\nimport lxml\";\n",
       "                var nbb_formatted_code = \"import json\\nimport requests\\nimport feedparser\\nfrom bs4 import BeautifulSoup\\nimport lxml\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import feedparser\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"def corpus_stats(corpus):\\n    print(\\\"Corpus Statistics\\\")\\n    print(\\\"Number of documents: \\\" + str(len(corpus.fileids())))\\n    print(\\\"Number of paragraphs: \\\" + str(len(corpus.paras())))\\n    print(\\\"Number of sentences: \\\" + str(len(corpus.sents())))\\n    print(\\\"Number of words: \\\" + str(len(corpus.words())))\\n    print(\\\"Vocabulary: \\\" + str(len(set(w.lower() for w in corpus.words()))))\\n    print(\\\"Avg chars per word: \\\" + str(round(len(corpus.raw())/len(corpus.words()),1)))\\n    print(\\\"Avg words per sentence: \\\" + str(round(len(corpus.words())/len(corpus.sents()),1)))\";\n",
       "                var nbb_formatted_code = \"def corpus_stats(corpus):\\n    print(\\\"Corpus Statistics\\\")\\n    print(\\\"Number of documents: \\\" + str(len(corpus.fileids())))\\n    print(\\\"Number of paragraphs: \\\" + str(len(corpus.paras())))\\n    print(\\\"Number of sentences: \\\" + str(len(corpus.sents())))\\n    print(\\\"Number of words: \\\" + str(len(corpus.words())))\\n    print(\\\"Vocabulary: \\\" + str(len(set(w.lower() for w in corpus.words()))))\\n    print(\\n        \\\"Avg chars per word: \\\" + str(round(len(corpus.raw()) / len(corpus.words()), 1))\\n    )\\n    print(\\n        \\\"Avg words per sentence: \\\"\\n        + str(round(len(corpus.words()) / len(corpus.sents()), 1))\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def corpus_stats(corpus):\n",
    "    print(\"Corpus Statistics\")\n",
    "    print(\"Number of documents: \" + str(len(corpus.fileids())))\n",
    "    print(\"Number of paragraphs: \" + str(len(corpus.paras())))\n",
    "    print(\"Number of sentences: \" + str(len(corpus.sents())))\n",
    "    print(\"Number of words: \" + str(len(corpus.words())))\n",
    "    print(\"Vocabulary: \" + str(len(set(w.lower() for w in corpus.words()))))\n",
    "    print(\"Avg chars per word: \" + str(round(len(corpus.raw())/len(corpus.words()),1)))\n",
    "    print(\"Avg words per sentence: \" + str(round(len(corpus.words())/len(corpus.sents()),1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lZ3ytdXA34PR"
   },
   "source": [
    "### Iterate through the list of article URLs below, scraping the text from each one and saving it to a text file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mDbZqPpT34PU"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"articles = [\\n    \\\"http://lite.cnn.io/en/article/h_eac18760a7a7f9a1bf33616f1c4a336d\\\",\\n    \\\"http://lite.cnn.io/en/article/h_de3f82f17d289680dd2b47c6413ebe7c\\\",\\n    \\\"http://lite.cnn.io/en/article/h_72f4dc9d6f35458a89af014b62e625ad\\\",\\n    \\\"http://lite.cnn.io/en/article/h_aa21fe6bf176071cb49e09d422c3adf0\\\",\\n    \\\"http://lite.cnn.io/en/article/h_8ad34a532921c9076cdc9d7390d2f1bc\\\",\\n    \\\"http://lite.cnn.io/en/article/h_84422c79110d9989177cfaf1c5f45fe7\\\",\\n    \\\"http://lite.cnn.io/en/article/h_d010d9580abac3a44c6181ec6fb63d58\\\",\\n    \\\"http://lite.cnn.io/en/article/h_fb11f4e9d7c5323e75b337d9e9e5e368\\\",\\n    \\\"http://lite.cnn.io/en/article/h_7b27f0b131067f8ece6238ac559670ab\\\",\\n    \\\"http://lite.cnn.io/en/article/h_8cae7f735fa9573d470f802063ceffe2\\\",\\n    \\\"http://lite.cnn.io/en/article/h_72c3668280e82576fcc2602b0fa70c14\\\",\\n    \\\"http://lite.cnn.io/en/article/h_d20658fb0e20212051cda0e0a7248c8a\\\",\\n    \\\"http://lite.cnn.io/en/article/h_56611c43d7928120d2ae21666ccc7417\\\",\\n    \\\"http://lite.cnn.io/en/article/h_bda0394e3c5ee7054ee65c022bca7695\\\",\\n]\";\n",
       "                var nbb_formatted_code = \"articles = [\\n    \\\"http://lite.cnn.io/en/article/h_eac18760a7a7f9a1bf33616f1c4a336d\\\",\\n    \\\"http://lite.cnn.io/en/article/h_de3f82f17d289680dd2b47c6413ebe7c\\\",\\n    \\\"http://lite.cnn.io/en/article/h_72f4dc9d6f35458a89af014b62e625ad\\\",\\n    \\\"http://lite.cnn.io/en/article/h_aa21fe6bf176071cb49e09d422c3adf0\\\",\\n    \\\"http://lite.cnn.io/en/article/h_8ad34a532921c9076cdc9d7390d2f1bc\\\",\\n    \\\"http://lite.cnn.io/en/article/h_84422c79110d9989177cfaf1c5f45fe7\\\",\\n    \\\"http://lite.cnn.io/en/article/h_d010d9580abac3a44c6181ec6fb63d58\\\",\\n    \\\"http://lite.cnn.io/en/article/h_fb11f4e9d7c5323e75b337d9e9e5e368\\\",\\n    \\\"http://lite.cnn.io/en/article/h_7b27f0b131067f8ece6238ac559670ab\\\",\\n    \\\"http://lite.cnn.io/en/article/h_8cae7f735fa9573d470f802063ceffe2\\\",\\n    \\\"http://lite.cnn.io/en/article/h_72c3668280e82576fcc2602b0fa70c14\\\",\\n    \\\"http://lite.cnn.io/en/article/h_d20658fb0e20212051cda0e0a7248c8a\\\",\\n    \\\"http://lite.cnn.io/en/article/h_56611c43d7928120d2ae21666ccc7417\\\",\\n    \\\"http://lite.cnn.io/en/article/h_bda0394e3c5ee7054ee65c022bca7695\\\",\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "articles = [\n",
    "    \"http://lite.cnn.io/en/article/h_eac18760a7a7f9a1bf33616f1c4a336d\",\n",
    "    \"http://lite.cnn.io/en/article/h_de3f82f17d289680dd2b47c6413ebe7c\",\n",
    "    \"http://lite.cnn.io/en/article/h_72f4dc9d6f35458a89af014b62e625ad\",\n",
    "    \"http://lite.cnn.io/en/article/h_aa21fe6bf176071cb49e09d422c3adf0\",\n",
    "    \"http://lite.cnn.io/en/article/h_8ad34a532921c9076cdc9d7390d2f1bc\",\n",
    "    \"http://lite.cnn.io/en/article/h_84422c79110d9989177cfaf1c5f45fe7\",\n",
    "    \"http://lite.cnn.io/en/article/h_d010d9580abac3a44c6181ec6fb63d58\",\n",
    "    \"http://lite.cnn.io/en/article/h_fb11f4e9d7c5323e75b337d9e9e5e368\",\n",
    "    \"http://lite.cnn.io/en/article/h_7b27f0b131067f8ece6238ac559670ab\",\n",
    "    \"http://lite.cnn.io/en/article/h_8cae7f735fa9573d470f802063ceffe2\",\n",
    "    \"http://lite.cnn.io/en/article/h_72c3668280e82576fcc2602b0fa70c14\",\n",
    "    \"http://lite.cnn.io/en/article/h_d20658fb0e20212051cda0e0a7248c8a\",\n",
    "    \"http://lite.cnn.io/en/article/h_56611c43d7928120d2ae21666ccc7417\",\n",
    "    \"http://lite.cnn.io/en/article/h_bda0394e3c5ee7054ee65c022bca7695\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AfDWUtDr34PX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BgGlAM2X34Pc"
   },
   "source": [
    "### Ingest the text files generated via web scraping into a corpus and print the corpus statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mmybAnNB34Pf"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"cnn_articles = []\\nfor article in articles:\\n    response = requests.get(article)\\n    content = response.text\\n    cnn_articles.append(content)\";\n",
       "                var nbb_formatted_code = \"cnn_articles = []\\nfor article in articles:\\n    response = requests.get(article)\\n    content = response.text\\n    cnn_articles.append(content)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_articles = []\n",
    "for article in articles:\n",
    "    response = requests.get(article)\n",
    "    content = response.text\n",
    "    cnn_articles.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"soup = BeautifulSoup(cnn_articles[7], \\\"html\\\")\\n# text_list = [tag.get_text() for tag in soup.find_all(TAGS)]\\n# title = soup.find_all(\\\"h2\\\")[0].text\\narticle = soup.find(\\\"div\\\", class_=\\\"afe4286c\\\").find_all([\\\"p\\\"])\\ntext_list = [tag.get_text() for tag in article]\\ntext = \\\" \\\".join(text_list)\\ntext = text.encode(\\\"UTF-8\\\")\\nfile = open(\\\"cnn_lite_corpus\\\\\\\\file.txt\\\", \\\"wb\\\")\\nfile.write(text)\\nfile.close()\";\n",
       "                var nbb_formatted_code = \"soup = BeautifulSoup(cnn_articles[7], \\\"html\\\")\\n# text_list = [tag.get_text() for tag in soup.find_all(TAGS)]\\n# title = soup.find_all(\\\"h2\\\")[0].text\\narticle = soup.find(\\\"div\\\", class_=\\\"afe4286c\\\").find_all([\\\"p\\\"])\\ntext_list = [tag.get_text() for tag in article]\\ntext = \\\" \\\".join(text_list)\\ntext = text.encode(\\\"UTF-8\\\")\\nfile = open(\\\"cnn_lite_corpus\\\\\\\\file.txt\\\", \\\"wb\\\")\\nfile.write(text)\\nfile.close()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "soup = BeautifulSoup(cnn_articles[7], \"html\")\n",
    "# text_list = [tag.get_text() for tag in soup.find_all(TAGS)]\n",
    "# title = soup.find_all(\"h2\")[0].text\n",
    "article = soup.find(\"div\", class_=\"afe4286c\").find_all([\"p\"])\n",
    "text_list = [tag.get_text() for tag in article]\n",
    "text = \" \".join(text_list)\n",
    "text = text.encode(\"UTF-8\")\n",
    "file = open(\"cnn_lite_corpus\\\\file.txt\", \"wb\")\n",
    "file.write(text)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"TAGS = [\\\"h1\\\", \\\"h2\\\", \\\"h3\\\", \\\"h4\\\", \\\"h5\\\", \\\"h6\\\", \\\"h7\\\", \\\"p\\\", \\\"li\\\"]\\ndocs = []\\nfor i, content in enumerate(cnn_articles):\\n    soup = BeautifulSoup(content, \\\"html\\\")\\n    article = soup.find(\\\"div\\\", class_=\\\"afe4286c\\\").find_all([\\\"p\\\"])\\n    text_list = [tag.get_text() for tag in article]\\n    text = \\\" \\\".join(text_list)\\n    text = text.encode(\\\"UTF-8\\\")\\n    title = soup.find_all(\\\"h2\\\")[0].text\\n\\n    file = open(\\\"cnn_lite_corpus\\\\\\\\article\\\" + str(i) + \\\".txt\\\", \\\"wb\\\")\\n    file.write(text)\\n    file.close()\\n# save to file instead\\n# docs.append(text)\";\n",
       "                var nbb_formatted_code = \"TAGS = [\\\"h1\\\", \\\"h2\\\", \\\"h3\\\", \\\"h4\\\", \\\"h5\\\", \\\"h6\\\", \\\"h7\\\", \\\"p\\\", \\\"li\\\"]\\ndocs = []\\nfor i, content in enumerate(cnn_articles):\\n    soup = BeautifulSoup(content, \\\"html\\\")\\n    article = soup.find(\\\"div\\\", class_=\\\"afe4286c\\\").find_all([\\\"p\\\"])\\n    text_list = [tag.get_text() for tag in article]\\n    text = \\\" \\\".join(text_list)\\n    text = text.encode(\\\"UTF-8\\\")\\n    title = soup.find_all(\\\"h2\\\")[0].text\\n\\n    file = open(\\\"cnn_lite_corpus\\\\\\\\article\\\" + str(i) + \\\".txt\\\", \\\"wb\\\")\\n    file.write(text)\\n    file.close()\\n# save to file instead\\n# docs.append(text)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TAGS = [\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\", \"h7\", \"p\", \"li\"]\n",
    "docs = []\n",
    "for i, content in enumerate(cnn_articles):\n",
    "    soup = BeautifulSoup(content, \"html\")\n",
    "    article = soup.find(\"div\", class_=\"afe4286c\").find_all([\"p\"])\n",
    "    text_list = [tag.get_text() for tag in article]\n",
    "    text = \" \".join(text_list)\n",
    "    text = text.encode(\"UTF-8\")\n",
    "    title = soup.find_all(\"h2\")[0].text\n",
    "\n",
    "    file = open(\"cnn_lite_corpus\\\\article\" + str(i) + \".txt\", \"wb\")\n",
    "    file.write(text)\n",
    "    file.close()\n",
    "# save to file instead\n",
    "# docs.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"PATH = \\\"cnn_lite_corpus/\\\"\\nDOC_PATTERN = r\\\".*\\\\.txt\\\"\\ncnn_corpus = PlaintextCorpusReader(PATH, DOC_PATTERN)\";\n",
       "                var nbb_formatted_code = \"PATH = \\\"cnn_lite_corpus/\\\"\\nDOC_PATTERN = r\\\".*\\\\.txt\\\"\\ncnn_corpus = PlaintextCorpusReader(PATH, DOC_PATTERN)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PATH = \"cnn_lite_corpus/\"\n",
    "DOC_PATTERN = r\".*\\.txt\"\n",
    "cnn_corpus = PlaintextCorpusReader(PATH, DOC_PATTERN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dgump\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"import nltk\\n\\nnltk.download(\\\"punkt\\\")\";\n",
       "                var nbb_formatted_code = \"import nltk\\n\\nnltk.download(\\\"punkt\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Statistics\n",
      "Number of documents: 15\n",
      "Number of paragraphs: 15\n",
      "Number of sentences: 595\n",
      "Number of words: 14625\n",
      "Vocabulary: 2895\n",
      "Avg chars per word: 5.0\n",
      "Avg words per sentence: 24.6\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"corpus_stats(cnn_corpus)\";\n",
       "                var nbb_formatted_code = \"corpus_stats(cnn_corpus)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus_stats(cnn_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sGP_4yfR34Pi"
   },
   "source": [
    "### Parse the O'Reilly Radar RSS feed below, extract the text from each post, and save it to a text file.\n",
    "\n",
    "The content of each post contains HTML tags. Strip those out using the same approach you used for web scraping so that only text is saved to the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CDbqkFCF34Pl"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"feed = \\\"http://feeds.feedburner.com/oreilly/radar/atom\\\"\";\n",
       "                var nbb_formatted_code = \"feed = \\\"http://feeds.feedburner.com/oreilly/radar/atom\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feed = \"http://feeds.feedburner.com/oreilly/radar/atom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l-a9JgWH34Po"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "replace() argument 1 must be str, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-df052b429e05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mparsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeedparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mposts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mposts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'>'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# test_rss = posts[0].content[0].value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# test_rss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: replace() argument 1 must be str, not list"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"parsed = feedparser.parse(feed)\\nposts = parsed.entries\\nposts[0].title.replace([\\\":\\\", '>'], \\\"\\\")\\n# test_rss = posts[0].content[0].value\\n# test_rss\";\n",
       "                var nbb_formatted_code = \"parsed = feedparser.parse(feed)\\nposts = parsed.entries\\nposts[0].title.replace([\\\":\\\", \\\">\\\"], \\\"\\\")\\n# test_rss = posts[0].content[0].value\\n# test_rss\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parsed = feedparser.parse(feed)\n",
    "posts = parsed.entries\n",
    "posts[0].title.replace(\":\", \"\")\n",
    "# test_rss = posts[0].content[0].value\n",
    "# test_rss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Radar trends to watch: November 2020',\n",
       " 'title_detail': {'type': 'text/plain',\n",
       "  'language': None,\n",
       "  'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "  'value': 'Radar trends to watch: November 2020'},\n",
       " 'links': [{'rel': 'alternate',\n",
       "   'type': 'text/html',\n",
       "   'href': 'http://feedproxy.google.com/~r/oreilly/radar/atom/~3/7S_cHstbl8Y/'}],\n",
       " 'link': 'http://feedproxy.google.com/~r/oreilly/radar/atom/~3/7S_cHstbl8Y/',\n",
       " 'comments': 'https://www.oreilly.com/radar/radar-trends-to-watch-november-2020/#respond',\n",
       " 'published': 'Mon, 02 Nov 2020 12:28:14 +0000',\n",
       " 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=2, tm_hour=12, tm_min=28, tm_sec=14, tm_wday=0, tm_yday=307, tm_isdst=0),\n",
       " 'authors': [{'name': 'Mike Loukides'}],\n",
       " 'author': 'Mike Loukides',\n",
       " 'author_detail': {'name': 'Mike Loukides'},\n",
       " 'tags': [{'term': 'Radar Trends', 'scheme': None, 'label': None},\n",
       "  {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       " 'id': 'https://www.oreilly.com/radar/?p=13388',\n",
       " 'guidislink': False,\n",
       " 'summary': 'Perhaps the most important event this month isn’t technical, but the start of the US Justice Dept.’s lawsuit against Google. That will certainly play out over years rather than months, but it’s significance is less about this particular case than the idea that legal and regulatory systems will play a large role in the evolution [&#8230;]',\n",
       " 'summary_detail': {'type': 'text/html',\n",
       "  'language': None,\n",
       "  'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "  'value': 'Perhaps the most important event this month isn’t technical, but the start of the US Justice Dept.’s lawsuit against Google. That will certainly play out over years rather than months, but it’s significance is less about this particular case than the idea that legal and regulatory systems will play a large role in the evolution [&#8230;]'},\n",
       " 'content': [{'type': 'text/html',\n",
       "   'language': None,\n",
       "   'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "   'value': '<p>Perhaps the most important event this month isn’t technical, but the start of the US Justice Dept.’s lawsuit against Google. That will certainly play out over years rather than months, but it’s significance is less about this particular case than the idea that legal and regulatory systems will play a large role in the evolution of technology in the US. In the short term, it’s worth watching the CPPA, GDPR, California’s Props 22 and 24, and FCC interference with social media’s enforcement of rules around community behavior.&nbsp; Long term, this is only the beginning.</p>\\n\\n\\n\\n<h3>Artificial Intelligence and Machine Learning</h3>\\n\\n\\n\\n<ul><li>Partial differential equations are the key to a number of difficult and important problems.&nbsp;In a surprising breakthrough, it’s been shown that deep learning can be used to <a href=\"https://www.technologyreview.com/2020/10/30/1011435/ai-fourier-neural-network-cracks-navier-stokes-and-partial-differential-equations/\">solve PDEs</a>, and that they are orders of magnitude faster than typical numerical methods.<br /></li><li><a href=\"https://www.agence.ai/\">Agence</a> is a dynamic film/multiplayer VR game with intelligent agents. AI might not be what pushes VR to commercial success, but it will certainly be a part.<br /></li><li><a href=\"https://www.udel.edu/udaily/2020/october/artificial-intelligence-model-dion-vlachos-josh-lansford/\">Towards more trustworthy models</a>: Research on models that can take into account physical laws, error, and missing information makes <a href=\"https://advances.sciencemag.org/content/6/42/eabc3204/tab-article-info\">AI more trustworthy</a>.<br /></li><li>“<a href=\"https://arxiv.org/abs/2009.08449\">Less than one shot learning</a>”: when the number of classes is larger than the number of sample. The key idea here is “soft labelling,” which allows labels to represent characteristics shared between multiple items in the sample.<br /></li><li><a href=\"https://www.nature.com/articles/s42256-020-00237-3\">Very small neural networks</a> adapted from worms’ nervous systems are able to perform tasks as well as networks thousands of times larger.<br /></li><li>A device that can <a href=\"https://spectrum.ieee.org/nanoclast/semiconductors/devices/memristor-first-single-device-to-act-like-a-neuron\">mimic the behavior of a neuron</a> might eventually make it possible to emulate a brain, without requiring a lot of power.<br /></li><li>AI is not magic, even when it is effective. <a href=\"https://datasociety.net/library/repairing-innovation/\">Integrating AI into medical practice</a> requires work–serious human work in rethinking social structures, communications, and hierarchies. This work frequently falls to the nursing staff, whose contribution is often undervalued.<br /></li><li><a href=\"https://github.com/daviddao/awful-ai\">Awful-AI</a> is a GitHub repo for tracking “awful uses of AI.”&nbsp; Autonomous weapons, racist AI, social credit, and scams: they’re all here. It would be funny if it wasn’t sad (and real).<br /></li><li>Pattern-exploited training (<a href=\"https://arxiv.org/abs/2001.07676\">PET</a>) is a new NLP technique that, on some benchmarks, <a href=\"https://www.infoq.com/news/2020/10/training-exceeds-gpt3/\">exceeds GPT-3 performance</a> while only using 223 million parameters (as opposed to 175 billion). While 223 million is still a large number, that’s a factor of almost 1000 less than GPT-3.<br /></li><li>Does explainable AI actually increase trust?&nbsp; <a href=\"https://techxplore.com/news/2020-10-explanations-data-based-users-ai.html\">Perhaps not</a>. Explanations can be distortions (lies).&nbsp; Auditing is a more trustworthy approach.</li></ul>\\n\\n\\n\\n<h3>Infrastructure and Operations</h3>\\n\\n\\n\\n<ul><li>Microsoft’s Open Source <a href=\"https://thenewstack.io/the-dapr-distributed-runtime-nears-production-readiness/\">Dapr Distributed Runtime</a> is an abstraction layer on top of Kubernetes (and much more) to simplify building software that runs in a distributed multi-cloud environment.<br /></li><li><a href=\"https://thenewstack.io/is-cloud-waste-inevitable-as-companies-move-to-the-cloud/\">Cloud waste</a>: How much cloud spending is actually used? Perhaps as much as 45% is wasted on overprovisioning, unexpected costs, and resources that go unused.<br /></li><li>Building <a href=\"https://thenewstack.io/adrian-cockcroft-on-failover-theater-and-achieving-true-continuous-resilience/\">continuously resilient</a> systems starts with chaos engineering: Adrian Cockroft on failover theater, the cloud, and reliability.</li></ul>\\n\\n\\n\\n<h3>Programming</h3>\\n\\n\\n\\n<ul><li><a href=\"https://dev.to/karthik2206/no-it-is-not-shameful-for-a-developer-to-use-no-code-8pe\">An all no-code startup</a>: Yes, it’s possible.&nbsp; It’s time to start thinking about the no-code “stack.”<br /></li><li>The kernel within the Linux kernel: <a href=\"https://thenewstack.io/how-ebpf-turns-linux-into-a-programmable-kernel/\">eBPF</a> can run sandboxed programs within the kernel’s memory space; it’s a convenient way to write kernel extensions and, conceivably, to replace much of the existing kernel with an eBPF-based microkernel.<br /></li><li>It’s worth reading @sogrady’s thoughts on how <a href=\"https://redmonk.com/sogrady/2020/10/06/developer-experience-gap/?utm_source=feedly&amp;utm_medium=rss&amp;utm_campaign=developer-experience-gap\">developer experience</a> needs to change in order to build more tightly integrated software across multiple platforms.</li></ul>\\n\\n\\n\\n<h3>Security and Privacy</h3>\\n\\n\\n\\n<ul><li>Botched <a href=\"https://thenewstack.io/palo-alto-networks-botched-access-management-an-easy-opening-for-cloud-attacks/\">identity and access management (IAM)</a> configuration is a huge problem for cloud security. Understanding security configuration is nearly impossible for humans.<br /></li><li><a href=\"https://arstechnica.com/gadgets/2020/10/future-of-collaboration-01/\">Redesigning corporate networks for working at home</a>: Corporate networks need to be re-thought; working from home raises new security issues and increases bandwidth requirements.<br /></li><li><a href=\"https://krebsonsecurity.com/2020/10/microsoft-uses-copyright-law-to-disrupt-trickbot-botnet/\">Microsoft disables Trickbot</a>, a ransomware network that was targeting the US election. What’s particularly interesting is that Microsoft used trademark law to get a court order allowing them to take control over the Trickbot servers.<br /></li><li>Have IoT vendors learned anything about security yet?&nbsp; Apparently not.&nbsp; <a href=\"https://arstechnica.com/information-technology/2020/09/how-a-hacker-turned-a-250-coffee-maker-into-ransom-machine/\">Your coffee maker on ransomware</a>.</li></ul>\\n\\n\\n\\n<h3>Economies</h3>\\n\\n\\n\\n<ul><li><a href=\"https://www.technologyreview.com/2020/10/13/1009497/singapore-vertical-farming-food-security/\">Indoor farming, food security, climate and COVID in Singapore</a>: how do you guarantee a food supply in the face of supply chain breakdowns and an increasingly erratic climate, in a densely populated country with almost no arable land?<br /></li><li><a href=\"https://www.ecb.europa.eu/euro/html/digitaleuro.en.html\">Towards a digital Euro</a>: The European Central Bank is taking the first steps towards a digital version of the Euro.&nbsp; It’s behind China (but ahead of the US) in its steps towards digital currency.</li></ul>\\n\\n\\n\\n<h3>Hardware</h3>\\n\\n\\n\\n<ul><li>Quantum fast fourier transform (<a href=\"https://link.springer.com/article/10.1007/s11128-020-02776-5\">QFFT</a>): Want to reinvent digital signal processing on quantum computers? This is another game changer, and one of the few classical algorithms that have been reinvented for quantum computers.<br /></li><li><a href=\"https://techxplore.com/news/2020-10-multi-state-storage-binary.html\">Multi-state memory:</a> not just zeros and ones. Moore’s law applies to memory, too, and the best way to get around the fundamental limitation (ever-smaller features) might be to design memory that goes <a href=\"https://pubs.acs.org/doi/10.1021/acsami.0c10184\">beyond binary</a>. Multi-state memory might also be a big step forward in neuromorphic computing.<br /></li><li><a href=\"https://techxplore.com/news/2020-10-wearable-sensors-skin.html\">Printing sensors directly on the body without heat</a>: Who needs an iPhone? These sensors could be revolutionary for tasks like COVID monitoring and personalized medicine.<br /></li><li><a href=\"https://www.techspot.com/news/86943-yale-scientists-have-developed-flexible-robotic-fabric.html\">Robotic fabric</a>: Developers have made fabric that can change its shape programmably.&nbsp; Robotic clothes? </li></ul>\\n\\n\\n\\n<h3>Web</h3>\\n\\n\\n\\n<ul><li>Do Not Track failed. <a href=\"https://arstechnica.com/tech-policy/2020/10/coming-to-a-browser-near-you-a-new-way-to-keep-sites-from-selling-your-data/\">Global Privacy Control</a> (GPC) is essentially Do Not Track with legal teeth. Will it succeed?&nbsp; Currently implemented by the Brave browser and some plugins for other browsers.<br /></li><li>Firefox’s campaign to “<a href=\"https://www.mozilla.org/en-US/firefox/unfck/\">Unfck the Internet</a>” gives us a reason to return to Firefox.&nbsp; The campaign is built around a set of plugins for controlling political ads, social media surveillance, warning others about inappropriate YouTube recommendations, and more. Putting social media control in the browser? It might work. </li></ul>\\n<img alt=\"\" height=\"1\" src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/7S_cHstbl8Y\" width=\"1\" />'}],\n",
       " 'wfw_commentrss': 'https://www.oreilly.com/radar/radar-trends-to-watch-november-2020/feed/',\n",
       " 'slash_comments': '0',\n",
       " 'feedburner_origlink': 'https://www.oreilly.com/radar/radar-trends-to-watch-november-2020/'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"posts[0]\";\n",
       "                var nbb_formatted_code = \"posts[0]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "posts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"for i, post in enumerate(posts):\\n    soup = BeautifulSoup(post.content[0].value, \\\"html\\\")\\n    tags = soup.find_all([\\\"p\\\", \\\"li\\\"])\\n    text_list = [tag.get_text() for tag in tags]\\n    text = \\\" \\\".join(text_list)\\n    text = text.encode(\\\"UTF-8\\\")\\n    title = post.title.replace(\\\":\\\", \\\"\\\")\\n    #     title = post.title.replace(\\\"<\\\", \\\"\\\")\\n    #     title = post.title.replace(\\\">\\\", \\\"\\\")\\n\\n    file = open(\\\"oreillyrss_corpus\\\\\\\\\\\" + title + \\\".txt\\\", \\\"wb\\\")\\n    file.write(text)\\n    file.close()\";\n",
       "                var nbb_formatted_code = \"for i, post in enumerate(posts):\\n    soup = BeautifulSoup(post.content[0].value, \\\"html\\\")\\n    tags = soup.find_all([\\\"p\\\", \\\"li\\\"])\\n    text_list = [tag.get_text() for tag in tags]\\n    text = \\\" \\\".join(text_list)\\n    text = text.encode(\\\"UTF-8\\\")\\n    title = post.title.replace(\\\":\\\", \\\"\\\")\\n    #     title = post.title.replace(\\\"<\\\", \\\"\\\")\\n    #     title = post.title.replace(\\\">\\\", \\\"\\\")\\n\\n    file = open(\\\"oreillyrss_corpus\\\\\\\\\\\" + title + \\\".txt\\\", \\\"wb\\\")\\n    file.write(text)\\n    file.close()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, post in enumerate(posts):\n",
    "    soup = BeautifulSoup(post.content[0].value, \"html\")\n",
    "    tags = soup.find_all([\"p\", \"li\"])\n",
    "    text_list = [tag.get_text() for tag in tags]\n",
    "    text = \" \".join(text_list)\n",
    "    text = text.encode(\"UTF-8\")\n",
    "    title = post.title.replace(\":\", \"\")\n",
    "    #     title = post.title.replace(\"<\", \"\")\n",
    "    #     title = post.title.replace(\">\", \"\")\n",
    "\n",
    "    file = open(\"oreillyrss_corpus\\\\\" + title + \".txt\", \"wb\")\n",
    "    file.write(text)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Statistics\n",
      "Number of documents: 60\n",
      "Number of paragraphs: 61\n",
      "Number of sentences: 2333\n",
      "Number of words: 57200\n",
      "Vocabulary: 6442\n",
      "Avg chars per word: 5.1\n",
      "Avg words per sentence: 24.5\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"corpus_stats(rss_corpus)\";\n",
       "                var nbb_formatted_code = \"corpus_stats(rss_corpus)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus_stats(rss_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SqK4w9sa34Pr"
   },
   "source": [
    "### Ingest the text files generated via RSS parsing into a corpus and print the corpus statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cd4x36-934Ps"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"PATH = \\\"oreillyrss_corpus/\\\"\\nDOC_PATTERN = r\\\".*\\\\.txt\\\"\\nrss_corpus = PlaintextCorpusReader(PATH, DOC_PATTERN)\";\n",
       "                var nbb_formatted_code = \"PATH = \\\"oreillyrss_corpus/\\\"\\nDOC_PATTERN = r\\\".*\\\\.txt\\\"\\nrss_corpus = PlaintextCorpusReader(PATH, DOC_PATTERN)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PATH = \"oreillyrss_corpus/\"\n",
    "DOC_PATTERN = r\".*\\.txt\"\n",
    "rss_corpus = PlaintextCorpusReader(PATH, DOC_PATTERN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9BDwjO8t34Pw"
   },
   "source": [
    "### Make an API call to the Hacker News API to retrieve their Ask, Show, and Job category items. \n",
    "\n",
    "- URL: https://hacker-news.firebaseio.com/v0/askstories.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W7vyWOSN34Px"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yEasqCkr34P0"
   },
   "source": [
    "### Once you have retrieved the item IDs from the URL above, retrieve each item by adding the item ID to the URL below, extract the item's text property, and save the text from each item to disk as its own document.\n",
    "\n",
    "- URL: https://hacker-news.firebaseio.com/v0/item/ITEM_ID_HERE.json\n",
    "\n",
    "The content of some items may contain HTML tags. Strip those out using the same approach you used for web scraping so that only text is saved to the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Vp7yfWB34P1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hw9-v8sK34P5"
   },
   "source": [
    "### Ingest the text files generated via API into a corpus and print the corpus statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dcsiPdkx34P7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Day 71, Lecture 2: Afternoon Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
